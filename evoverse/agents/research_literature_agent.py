"""
LiteratureAgent - MVP æ–‡çŒ®æ£€ç´¢ Agent

å°è£… UnifiedLiteratureSearchï¼Œæä¾›ï¼š
- search_and_summarizeï¼šæŒ‰æŸ¥è¯¢æ£€ç´¢æ–‡çŒ®å¹¶ç”¨ LLM åšç®€è¦æ‘˜è¦
"""

from typing import Any, Dict, List, Optional
import logging

from evoverse.agents.base_agent import BaseAgent
from evoverse.literature.unified_search import UnifiedLiteratureSearch
from evoverse.core.llm_client import LLMClient
import hashlib


logger = logging.getLogger(__name__)


class LiteratureAgent(BaseAgent):
    """MVP ç‰ˆæœ¬æ–‡çŒ® Agentã€‚"""

    def __init__(
        self,
        agent_id: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        llm_client: Optional[LLMClient] = None,
        searcher: Optional[UnifiedLiteratureSearch] = None,
    ):
        super().__init__(agent_id=agent_id, agent_type="LiteratureAgent", config=config)
        self.llm = llm_client or LLMClient(max_history=16)
        # é»˜è®¤å…³é—­ Semantic Scholarï¼Œä»¥å‡å°‘ç½‘ç»œä¾èµ–å’Œä¸ç¨³å®šæ€§
        self.searcher = searcher or UnifiedLiteratureSearch(
            semantic_scholar_enabled=False
        )

    @staticmethod
    def _build_global_id(
        source: Optional[str],
        primary_id: Optional[str],
        title: str,
        year: Optional[int],
    ) -> str:
        """
        ä¸ºæ¯ç¯‡è®ºæ–‡æ„é€ ä¸€ä¸ªå…¨å±€å”¯ä¸€çš„é€»è¾‘ IDï¼Œç±»ä¼¼ Kosmosï¼š
        arxiv:2511.02824
        pubmed:12345678
        semanticscholar:abcdef1234
        å¦‚æœç¼ºå°‘ primary_idï¼Œå°±ç”¨ title+year åšä¸€ä¸ªçŸ­ hashã€‚
        """
        src = (source or "unknown").lower()

        # ä¼˜å…ˆç”¨ source + primary_id
        if primary_id:
            pid = str(primary_id).strip()
            return f"{src}:{pid}"

        # å…œåº•ï¼šç”¨æ ‡é¢˜ + å¹´ä»½æ„é€ ä¸€ä¸ªç¨³å®š hash
        base = f"{title}|{year or ''}".encode("utf-8")
        digest = hashlib.sha1(base).hexdigest()[:16]
        return f"{src}:{digest}"

    def search_and_summarize(
        self,
        query: str,
        max_results: int = 20,
    ) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢æ–‡çŒ®å¹¶ä¸ºæ¯ç¯‡ç”Ÿæˆç®€çŸ­æ‘˜è¦ã€‚

        è¿”å›çš„æ¯ä¸ªå…ƒç´ æ˜¯ç»è¿‡ç²¾ç®€çš„ dictï¼Œæ–¹ä¾¿åç»­åºåˆ—åŒ–å’Œ prompt ä½¿ç”¨ï¼š
        {
            "title": ...,
            "authors": [...],
            "year": ...,
            "abstract": ...,
            "summary": ...,
            "source": ...,
            "primary_id": ...
        }
        """
        logger.info("LiteratureAgent searching papers: %s", query)
        papers = self.searcher.search(
            query=query,
            max_results_per_source=max_results,
            total_max_results=max_results,
            deduplicate=True,
            extract_full_text=False,
        )
        for i, p in enumerate(papers, start=1):
            logger.info(
                "Paper %d: [%s] %s",
                i,
                getattr(p, "primary_identifier", getattr(p, "id", "")),
                getattr(p, "title", ""),
            )

        simplified: List[Dict[str, Any]] = []
        for p in papers:
            simplified.append(self._simplify_paper(p))

        # ç”¨ LLM ç”Ÿæˆæ‘˜è¦ï¼ˆæ‰¹é‡å¤„ç†å¯ä»¥åç»­ä¼˜åŒ–ï¼ŒMVP å…ˆç®€å•é€ç¯‡ï¼‰
        for item in simplified:
            item["summary"] = self._summarize_paper(item)

        logger.info("LiteratureAgent retrieved %d papers", len(simplified))
        return simplified

    def _simplify_paper(self, paper: Any) -> Dict[str, Any]:
        """å°† PaperMetadata å‹ç¼©æˆæ˜“äºä¼ è¾“å’Œåºåˆ—åŒ–çš„å­—å…¸ï¼Œå¹¶è¡¥å……ç»Ÿä¸€ IDã€‚"""
        # 1. å–åŸºç¡€å­—æ®µ
        title = getattr(paper, "title", "") or ""
        authors = getattr(paper, "authors", []) or []
        year = getattr(paper, "year", None)
        abstract = getattr(paper, "abstract", None) or getattr(paper, "summary", "")
        source = getattr(paper, "source", None)
        primary_id = getattr(paper, "primary_identifier", None)

        # 2. è§„èŒƒä½œè€…åˆ—è¡¨ä¸º List[str]
        norm_authors: List[str] = []
        for a in authors:
            if isinstance(a, str):
                norm_authors.append(a)
            else:
                name = getattr(a, "name", None) or str(a)
                norm_authors.append(name)

        # 3. è§„èŒƒ source ä¸ºå­—ç¬¦ä¸²
        if source is None:
            source_str = "unknown"
        else:
            source_str = getattr(source, "value", str(source)).lower()

        # 4. æ„é€ ç»Ÿä¸€é€»è¾‘ IDï¼ˆå’Œ Kosmos ä¸€æ ·çš„æ€è·¯ï¼‰
        global_id = self._build_global_id(
            source=source_str,
            primary_id=primary_id,
            title=title,
            year=year,
        )

        # 5. è¿”å›å¸¦ id çš„ç®€åŒ–ç»“æ„
        return {
            "id": global_id,          # ğŸ”´ ç»Ÿä¸€çš„å†…éƒ¨ IDï¼ˆåé¢æ‰€æœ‰åœ°æ–¹éƒ½ç”¨å®ƒï¼‰
            "source": source_str,     # æ–‡çŒ®æ¥æºï¼šarxiv / pubmed / semanticscholar / unknown
            "primary_id": primary_id, # åŸå§‹ source çš„ä¸»é”®ï¼Œæ–¹ä¾¿ debug æˆ–å¤–éƒ¨è·³è½¬
            "title": title,
            "authors": norm_authors,
            "year": year,
            "abstract": abstract,
            "summary": "",            # è¿™é‡Œå…ˆç•™ç©ºï¼Œåé¢ _summarize_paper å†å¡«
        }
    

    def _summarize_paper(self, paper: Dict[str, Any]) -> str:
        """ä½¿ç”¨ LLM ä¸ºå•ç¯‡æ–‡çŒ®ç”Ÿæˆ 2-3 å¥ä¸­æ–‡æ‘˜è¦ã€‚"""
        title = paper.get("title", "")
        abstract = paper.get("abstract", "")

        if not abstract:
            return ""

        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ç§‘ç ”åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ç”¨ 2-3 å¥æ€»ç»“è®ºæ–‡è¦ç‚¹ã€‚",
            },
            {
                "role": "user",
                "content": f"è®ºæ–‡æ ‡é¢˜ï¼š{title}\n\næ‘˜è¦ï¼š{abstract}",
            },
        ]

        try:
            summary = self.llm.chat(messages)
        except Exception as exc:  # noqa: BLE001
            logger.warning("LLM summarize paper failed: %s", exc)
            summary = ""

        return summary
